{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import yaml\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import OAuthHandler\n",
    "from tweepy.api import API as Twitter\n",
    "from tweepy.error import TweepError\n",
    "from tweepy.parsers import JSONParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x1b7bb8f1710>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x1b7bcfbcb28>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x1b7bcfbcb88>)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjc\\Anaconda3\\envs\\nlp-workshop\\lib\\site-packages\\ipykernel_launcher.py:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "stream = open('C:/Users/jjc/Misc/twitter_api_details.yml', \"r\")\n",
    "conf = yaml.load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'twitter': {'api': {'pause': 1,\n",
       "   'app': {'key': 'X9JqOAFJ8GjYNqvEolEpvZdE2',\n",
       "    'secret': '4j5TdZC2o5YfSFnlASa10x9KLE3FN4P5FTOwHLSrx8FYYem7c1',\n",
       "    'token': '2620986611-pOP0uh0cEkgh8yxmJdNEpK3kD4DIKTSJvmKJxR6',\n",
       "    'token_secret': 'yslRiqrk6EriZxFmeWAkJItWOD9PtdVOLe3h5IaoskRVY'}}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = OAuthHandler(conf[\"twitter\"][\"api\"][\"app\"][\"key\"], conf[\"twitter\"][\"api\"][\"app\"][\"secret\"])\n",
    "auth.set_access_token(conf[\"twitter\"][\"api\"][\"app\"][\"token\"], conf[\"twitter\"][\"api\"][\"app\"][\"token_secret\"])\n",
    "twitter = Twitter(auth, parser=JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = twitter.search('#GoT', lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results['statuses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http_regexp = 'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)'\n",
    "http_regexp = 'https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,}A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://t.co/YbBI6vkzYh', 'https://t.co/j6XbRWYPqN']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(http_regexp,'I miss the old Tyrion #GoT #GameofThrones https://t.co/YbBI6vkzYh https://t.co/j6XbRWYPqN' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(http_regexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I miss the old Tyrion #GoT #GameofThrones  '"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern.sub('','I miss the old Tyrion #GoT #GameofThrones https://t.co/YbBI6vkzYh https://t.co/j6XbRWYPqN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    \n",
    "    return pattern.sub('',text)\n",
    "\n",
    "def remove_hashes(text):\n",
    "    \n",
    "    return text.replace('#','')\n",
    "\n",
    "def remove_newline(text):\n",
    "    return text.replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweets):\n",
    "    out_list=[]\n",
    "\n",
    "    for tweet in tweets['statuses']:\n",
    "        text= tweet['text']\n",
    "        url_clean = remove_urls(text)\n",
    "        hash_clean = remove_hashes(url_clean)\n",
    "        newline_clean = remove_newline(hash_clean)\n",
    "        out_list.append(newline_clean)\n",
    "        \n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_texts = clean_tweets(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT @SDinwiddie_25: Q: Favorite Game of Thrones scene AskSpencer - @DanParzych  A: GOT GameOfThrones K8IROS ',\n",
       " 'RT @dreadnstyn: If You Have 400k Less Followers  Follow me @dreadnstyn  100 Rts For 100 FollowersðŸ‡³ðŸ‡¬  200 Rts For 300 FollowersðŸ‡³ðŸ‡¬  300 Rts Fâ€¦',\n",
       " 'RT @dreadnstyn: If You Have 80k Less Followers  Follow me @dreadnstyn  500 Rts For 500 FollowersðŸ‡³ðŸ‡¬  600 Rts For 600 FollowersðŸ‡³ðŸ‡¬  700 Rts Foâ€¦',\n",
       " 'RT @dreadnstyn: If You Have 400k Less Followers  Follow me @dreadnstyn  100 Rts For 100 FollowersðŸ‡³ðŸ‡¬  200 Rts For 300 FollowersðŸ‡³ðŸ‡¬  300 Rts Fâ€¦',\n",
       " 'RT @dreadnstyn: If You Have 400k Less Followers  Follow me @dreadnstyn  100 Rts For 100 FollowersðŸ‡³ðŸ‡¬  200 Rts For 300 FollowersðŸ‡³ðŸ‡¬  300 Rts Fâ€¦',\n",
       " 'RT @dreadnstyn: If You Have 400k Less Followers  Follow me @dreadnstyn  100 Rts For 100 FollowersðŸ‡³ðŸ‡¬  200 Rts For 300 FollowersðŸ‡³ðŸ‡¬  300 Rts Fâ€¦',\n",
       " 'Repost @markmannphoto with make_repost ãƒ»ãƒ»ãƒ» @maisie_williams was pretty suprised watching got last week..â€¦ ',\n",
       " 'RT @dreadnstyn: If You Have 400k Less Followers  Follow me @dreadnstyn  100 Rts For 100 FollowersðŸ‡³ðŸ‡¬  200 Rts For 300 FollowersðŸ‡³ðŸ‡¬  300 Rts Fâ€¦',\n",
       " 'I miss the old Tyrion GoT GameofThrones  ',\n",
       " 'RT @madneon: @realDonaldTrump Someone has be catching up on GOT ',\n",
       " 'RT @RedditFreeFolk: The DnDâ€™s version... @ r/FreeFolk &gt;  GameofThrones GoT GoTtoGive freefolk ',\n",
       " \"Conan O'Brienne GoT GameofThrones  \",\n",
       " 'RT @awzurcher: Thereâ€™s the Mad King and thereâ€™s the Night King. There is no Mad Night King. If youâ€™re going to GOT, do it right, dammit. hâ€¦',\n",
       " '@realDonaldTrump Someone has be catching up on GOT ',\n",
       " 'Bend the knee at WW Day 2! . . . daenerystargaryen daenerystargaryencosplay gameofthrones gameofthronescosplayâ€¦ ']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': 'RT @dreadnstyn: If You Have 400k Less Followers  Follow me @dreadnstyn  100 Rts For 100 FollowersðŸ‡³ðŸ‡¬  200 Rts For 300 FollowersðŸ‡³ðŸ‡¬  300 Rts Fâ€¦', 'entities': (ðŸ‡¬  200, Rts For, 300, ðŸ‡¬  , Rts F)}\n",
      "{'sentence': 'RT @dreadnstyn: If You Have 80k Less Followers  Follow me @dreadnstyn  500 Rts For 500 FollowersðŸ‡³ðŸ‡¬  600 Rts For 600 FollowersðŸ‡³ðŸ‡¬  700 Rts Foâ€¦', 'entities': (600, ðŸ‡¬  , Rts Fo)}\n",
      "{'sentence': 'RT @dreadnstyn: If You Have 400k Less Followers  Follow me @dreadnstyn  100 Rts For 100 FollowersðŸ‡³ðŸ‡¬  200 Rts For 300 FollowersðŸ‡³ðŸ‡¬  300 Rts Fâ€¦', 'entities': (ðŸ‡¬  200, Rts For, 300, ðŸ‡¬  , Rts F)}\n",
      "{'sentence': 'RT @dreadnstyn: If You Have 400k Less Followers  Follow me @dreadnstyn  100 Rts For 100 FollowersðŸ‡³ðŸ‡¬  200 Rts For 300 FollowersðŸ‡³ðŸ‡¬  300 Rts Fâ€¦', 'entities': (ðŸ‡¬  200, Rts For, 300, ðŸ‡¬  , Rts F)}\n",
      "{'sentence': 'RT @dreadnstyn: If You Have 400k Less Followers  Follow me @dreadnstyn  100 Rts For 100 FollowersðŸ‡³ðŸ‡¬  200 Rts For 300 FollowersðŸ‡³ðŸ‡¬  300 Rts Fâ€¦', 'entities': (ðŸ‡¬  200, Rts For, 300, ðŸ‡¬  , Rts F)}\n",
      "{'sentence': 'Repost @markmannphoto with make_repost ãƒ»ãƒ»ãƒ» @maisie_williams was pretty suprised watching got last week..â€¦ ', 'entities': (@maisie_williams, last week)}\n",
      "{'sentence': 'RT @dreadnstyn: If You Have 400k Less Followers  Follow me @dreadnstyn  100 Rts For 100 FollowersðŸ‡³ðŸ‡¬  200 Rts For 300 FollowersðŸ‡³ðŸ‡¬  300 Rts Fâ€¦', 'entities': (ðŸ‡¬  200, Rts For, 300, ðŸ‡¬  , Rts F)}\n",
      "{'sentence': 'I miss the old Tyrion GoT GameofThrones  ', 'entities': (Tyrion GoT,)}\n",
      "{'sentence': 'RT @RedditFreeFolk: The DnDâ€™s version... @ r/FreeFolk &gt;  GameofThrones GoT GoTtoGive freefolk ', 'entities': (GameofThrones GoT,)}\n",
      "{'sentence': \"Conan O'Brienne GoT GameofThrones  \", 'entities': (Conan O'Brienne, GameofThrones)}\n",
      "{'sentence': 'Bend the knee at WW Day 2! . . . daenerystargaryen daenerystargaryencosplay gameofthrones gameofthronescosplayâ€¦ ', 'entities': (WW Day 2,)}\n"
     ]
    }
   ],
   "source": [
    "for sentence in cleaned_texts:\n",
    "    doc = nlp(sentence)\n",
    "    entities = doc.ents\n",
    "    if len(entities) > 0:\n",
    "        output = dict(\n",
    "            sentence=sentence,\n",
    "            entities=entities\n",
    "        )\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import load_data, text_classifier_learner, AWD_LSTM\n",
    "import torch\n",
    "from pathlib import Path, PosixPath, PurePosixPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce MX150'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PurePosixPath('model/sentiment')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=PurePosixPath('./model/sentiment')\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PurePosixPath('model/sentiment/data_clas.pkl')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path/'data_clas.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "cannot instantiate 'PosixPath' on your system",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-1b182c1c12b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#path=Path('c:/Users/jjc/Projects/pydata2019/pydata2019-nlp-system/step3_nlp/model/sentiment/')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata_clas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'data_clas.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mlearn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_classifier_learner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_clas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAWD_LSTM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_mult\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\fastai\\basic_data.py\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(path, file, bs, val_bs, num_workers, dl_tfms, device, collate_fn, no_check, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;34m\"Load a saved `DataBunch` from `path/file`. `file` can be file-like (file or buffer)\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfile\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_pathlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m     \u001b[0mll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m     return ll.databunch(path=path, bs=bs, val_bs=val_bs, num_workers=num_workers, dl_tfms=dl_tfms, device=device,\n\u001b[0;32m    279\u001b[0m                         collate_fn=collate_fn, no_check=no_check, **kwargs)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    572\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\pathlib.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1004\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flavour\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m             raise NotImplementedError(\"cannot instantiate %r on your system\"\n\u001b[1;32m-> 1006\u001b[1;33m                                       % (cls.__name__,))\n\u001b[0m\u001b[0;32m   1007\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: cannot instantiate 'PosixPath' on your system"
     ]
    }
   ],
   "source": [
    "bs=48\n",
    "#path=Path('c:/Users/jjc/Projects/pydata2019/pydata2019-nlp-system/step3_nlp/model/sentiment/')\n",
    "data_clas = load_data(path, 'data_clas.pkl', bs=bs)\n",
    "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
